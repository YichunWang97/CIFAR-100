import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

#Unpickle file
def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='latin1')
    return dict;

data_train = unpickle('./cifar-100-python/train')
train = data_train.get('data')
train_coarse_labels = data_train.get('coarse_labels')

#Grayscale preprocessing
train_image = train.reshape(-1,3,32,32)
train_image_gray = np.zeros(train_image.shape)
for i in range(0, train_image.shape[0]):
    r = train_image[i][0]
    g = train_image[i][1]
    b = train_image[i][2]
    grey = r*0.3+g*0.59+b*0.11
    image_grey = [grey, grey, grey]
    train_image_gray[i] = image_grey
train = train_image_gray.reshape(-1, 3072)

train = pd.DataFrame(train)
train_coarse_labels = pd.DataFrame(train_coarse_labels)

#Standardization
scaler = StandardScaler()
scaler.fit(train)
train = scaler.transform(trSain)

#Principal component analysis
pca = PCA(n_components = 0.8)
train = pca.fit_transform(train)

#Split data set
x_train, x_test, y_train, y_test = train_test_split(train, train_coarse_labels[0], test_size = 0.2)
x_train.shape

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

#Use RandomizedSearchCV to find parameters for the random forest algorithm (including 10 cross-validation)
n_estimators = [int(x) for x in np.linspace(start = 600, stop = 1000, num = 5)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(6, 20, num = 15)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap
              }

rf_coarse = RandomForestClassifier()
rf_random_coarse = RandomizedSearchCV(
    estimator = rf_coarse, 
    param_distributions = random_grid,
    n_iter = 20,
    scoring = 'accuracy', 
    cv = 10,
    verbose = 2,
    n_jobs = -1
)
rf_random_coarse.fit(x_train, y_train)

#The best parameters of random forest
rf_random_coarse.best_params_

#Get the best classifier
rfc_coarse = rf_random_coarse.best_estimator_
rfc_coarse.fit(x_train, y_train)

from sklearn.metrics import classification_report

#Generate classification_report for random forest
print("Random forest classification report for super class in Cifar-100")
print(classification_report(y_test, rfc_coarse.predict(x_test)))

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import matplotlib

#Generate confusion matrix for random forest
def confusion_matrix_plot(y_text, y_predict):
    matrix = confusion_matrix(y_text, y_predict)
    plt.matshow(matrix)
    plt.colorbar()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    return plt

print("Random forest confusion matrix for super class in Cifar-100")
confusion_matrix_plot(y_test, rfc_coarse.predict(x_test)).show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import pickle
import time

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

start = time.time()

def unpickle(file):
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='latin1')
    return dict;

def random_forest_classcifation(data_train_features, data_train_labels, data_test_features):
    train = data_train_features
    train_coarse_labels = data_train_labels
    test = data_test_features
    #test_coarse_labels = data_test.get('coarse_labels')

    total = np.vstack((train, test))
    total_image = total.reshape(-1,3,32,32)
    total_image_gray = np.zeros(total_image.shape)
    for i in range(0, total_image.shape[0]):
        r = total_image[i][0]
        g = total_image[i][1]
        b = total_image[i][2]
        grey = r*0.3+g*0.59+b*0.11
        image_grey = [grey, grey, grey]
        total_image_gray[i] = image_grey
    total = total_image_gray.reshape(-1, 3072)

    scaler_total = StandardScaler()
    scaler_total.fit(total)
    total = scaler_total.transform(total)

    pca_total = PCA(n_components = 0.8)
    total = pca_total.fit_transform(total)

    train = total[0:50000,:]
    test = total[50000:60000,:]

    random_forest = RandomForestClassifier(
        n_estimators = 600,
        min_samples_split = 10,
        min_samples_leaf = 1,
        max_features = 'sqrt',
        max_depth = 20,
        bootstrap = False
    )
    random_forest.fit(train, train_coarse_labels)
    return random_forest.predict(test)

data_train = unpickle('./cifar-100-python/train')
train = data_train.get('data')
train_coarse_labels = data_train.get('coarse_labels')
data_test = unpickle('./cifar-100-python/test')
test = data_test.get('data')

test_predict = random_forest_classcifation(train, train_coarse_labels, test)
test_coarse_labels = data_test.get('coarse_labels')

print("Random forest classification report for super class in Cifar-100")
print(classification_report(test_coarse_labels, test_predict))

def confusion_matrix_plot(y_text, y_predict):
    matrix = confusion_matrix(y_text, y_predict)
    plt.matshow(matrix)
    plt.colorbar()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    return plt

print("Random forest confusion matrix for super class in Cifar-100")
confusion_matrix_plot(test_coarse_labels, test_predict).show()   

print('Total running time', time.time() - start)
